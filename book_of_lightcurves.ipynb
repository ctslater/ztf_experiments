{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import axs\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from pyspark.sql.functions import size as spark_size\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from pyspark.sql.functions import min as spark_min\n",
    "from pyspark.sql.functions import max as spark_max\n",
    "\n",
    "matplotlib.rcParams['figure.dpi'] = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spark_start(project_path, metastore=None):\n",
    "    from pyspark.sql import SparkSession\n",
    "\n",
    "    warehouse_location = os.path.join(project_path, 'spark-warehouse')\n",
    "\n",
    "    local_dir = os.path.join(project_path, 'spark-tmp')\n",
    "\n",
    "    spark = ( \n",
    "            SparkSession.builder\n",
    "            .appName(\"LSD2\")\n",
    "            .config(\"spark.sql.warehouse.dir\", warehouse_location)\n",
    "            .config('spark.master', \"local[4]\")\n",
    "            .config('spark.driver.memory', '6G') # 128\n",
    "            .config('spark.local.dir', local_dir)\n",
    "            .config('spark.memory.offHeap.enabled', 'true')\n",
    "            .config('spark.memory.offHeap.size', '4G') # 256\n",
    "            .config(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "            .config(\"spark.driver.maxResultSize\", \"6G\")\n",
    "            .config(\"spark.driver.extraJavaOptions\", f\"-Dderby.system.home={metastore}\")\n",
    "            .enableHiveSupport()\n",
    "            .getOrCreate()\n",
    "                    )   \n",
    "\n",
    "    return spark\n",
    "\n",
    "spark_session = spark_start(\"/epyc/users/ctslater\")\n",
    "\n",
    "catalog = axs.AxsCatalog(spark_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ztf = catalog.load(\"ztf_1am_lc\")\n",
    "sesar_axs = catalog.load(\"sesar_rrlyrae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "matched = sesar_axs.crossmatch(ztf)\n",
    "matched_filtered = (matched.select(\"ra\", \"dec\", \"matchid\", \"Per\", \"weightedmeanmag\", \"filterid\", \"mjd\", \"psfflux\")\n",
    "                    .where((spark_size(matched['mjd']) > 5) &\n",
    "                           ((matched['S3ab'] > 0.8) | (matched['S3c'] > 0.8))\n",
    "                            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = matched_filtered.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Supress all output from this. This is a hack.\n",
    "\n",
    "\n",
    "figures = []\n",
    "for n in range(len(results)//4):\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2)\n",
    "    for m, ax in enumerate(axes.flatten()):\n",
    "        result_id = 4*n + m\n",
    "        this_source = results[result_id]\n",
    "\n",
    "        sel, = np.where(np.array(this_source['filterid']) == 1)\n",
    "        if(len(sel) > 0):\n",
    "            ax.plot(np.array(this_source['mjd'])[sel]/this_source[\"Per\"] % 1,\n",
    "                     np.array(this_source['psfflux'])[sel], '.')\n",
    "\n",
    "        sel, = np.where(np.array(this_source['filterid']) == 2)\n",
    "        if(len(sel) > 0):\n",
    "            ax.plot(np.array(this_source['mjd'])[sel]/this_source[\"Per\"] % 1,\n",
    "                     np.array(this_source['psfflux'])[sel], '.')\n",
    "\n",
    "\n",
    "        flux_std = np.std(this_source['psfflux'])\n",
    "        flux_mean = np.mean(this_source['psfflux'])\n",
    "        ax.set_ylim(flux_mean - 3*flux_std, flux_mean + 3*flux_std)\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_xlabel(\"Phase\")\n",
    "        ax.set_ylabel(\"Flux\")\n",
    "        ax.yaxis.set_ticklabels(\"\")\n",
    "        ax.xaxis.set_ticklabels([\"0\", \"\", \"\", \"\", \"\", \"1\"])\n",
    "\n",
    "        ax.text(0.85, 0.95, \"{:0.1f}\".format(this_source['weightedmeanmag']),\n",
    "                 fontsize=8, verticalalignment=\"top\",\n",
    "                 transform=ax.transAxes)\n",
    "        ax.text(0.05, 0.95, \"{:d}\".format(result_id),\n",
    "                 fontsize=8, verticalalignment=\"top\",\n",
    "                 transform=ax.transAxes)\n",
    "        \n",
    "    figures.append(fig)\n",
    "\n",
    "with PdfPages('ztf_lyrae.pdf') as pdf:            \n",
    "    for fig in figures:\n",
    "        pdf.savefig(fig);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-AXS Spark",
   "language": "python",
   "name": "spark-smj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
